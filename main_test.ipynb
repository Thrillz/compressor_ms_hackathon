{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter file runs the entire anomaly detection code for the compressor insights use case.\n",
    "\n",
    "from the import statements below, the main_util_script, does all the data cleaning and transformation and provides a dataframe and a list as output. To run the util script, the pressure ranges of the racks need to be supplied as input. The dataframe provided as output here can be split for different uses, those needed for compressor quadrants are selected and written to file, while ml_df, refers to data used as input for anomaly detection.\n",
    "\n",
    "Training_script trains the model, saves the scaling parameters used, model trained and results of the prediction to a file unique to the rack that calls the script. Prediction script is run if a result.csv file exists for the rack.\n",
    "\n",
    "The threshold script contains the dates that were flagged as anomalies as well as the alarm parameter that is either set to true or false. Alarm parameter is set to true when we have 14 consecutive days flagged as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pressure_range_script import pressure_range_dict\n",
    "from main_util_script import aggregate_dataframe\n",
    "from training_script import model_train\n",
    "from threshold_script import threshold\n",
    "from prediction import run_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 2000\n",
    "pd.options.display.max_columns = 2000\n",
    "seperator = '_'\n",
    "path = 'C:/Users/U378246/Documents/ECS_data_analysis_notebooks/Data/'\n",
    "filename = 'wm67.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['SiteID', 'SiteName', 'AssetID', 'AssetName', 'PointName', 'DataValue', 'Timetag', 'Units', 'PropertyName']\n",
    "df = pd.read_csv(path+filename, names=colnames, header=None)\n",
    "site_id = df.SiteID.unique()[0]\n",
    "pressure_range = pressure_range_dict.get(site_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = aggregate_dataframe(df,site_id, suc_pres_range=pressure_range)\n",
    "data,rack_names = data_agg.aggregate_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendDFToCSV_void(df, csvFilePath, sep=\",\"):\n",
    "    if not os.path.isfile(csvFilePath):\n",
    "        df.to_csv(csvFilePath, mode='a', index=True, sep=sep)\n",
    "    else:\n",
    "        df.to_csv(csvFilePath, mode='a', index=True, sep=sep, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrants_df = data.filter(regex='Runtime|Switch|% Capacity|Neutral|Quadrant')\n",
    "quadrants_df['SiteID'] = site_id\n",
    "quadrant_filename = 'quadrants.csv'\n",
    "appendDFToCSV_void(quadrants_df, quadrant_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df = data[data.columns.drop(list(data.filter(regex='% Capacity|Neutral|Quadrant')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_racks(df, rack_var):\n",
    "    var_name = rack_var[-1:].upper()\n",
    "    rack_name = df.loc[:, df.columns.str.contains('{}$|{}\\s[0-9]*$|{}\\s'.format(var_name, var_name, var_name))]\n",
    "    return rack_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "racks = [0]*len(rack_names)\n",
    "result = [0]*len(rack_names)\n",
    "\n",
    "for i,j in enumerate(rack_names):\n",
    "    rack_names[i] = rack_names[i].replace(\" \", \"_\")\n",
    "    alarm_file = str(site_id)+ seperator+ rack_names[i]+ '_flags.csv'\n",
    "    result_file= str(site_id)+ seperator+ rack_names[i]+ '_results.csv'\n",
    "    racks[i] = get_racks(ml_df, j)\n",
    "    \n",
    "    if os.path.isfile(result_file):\n",
    "        scaler_file = str(site_id)+ seperator+ rack_names[i]+ '_std_scaler.bin'\n",
    "        model_file  = str(site_id)+ seperator+ rack_names[i]+ '_model.bin'\n",
    "        run_predict(racks[i], scaler_file, model_file, result_file)\n",
    "        \n",
    "        prev_result = pd.read_csv(result_file, index_col='Timetag')\n",
    "        prev_result = prev_result[~prev_result.index.duplicated(keep='last')]\n",
    "        prev_result.to_csv(result_file)\n",
    "        \n",
    "        prev_alarm = pd.read_csv(alarm_file)\n",
    "        prev_alarm = prev_alarm.drop_duplicates(subset = ['Timetag', 'alarm'])\n",
    "        prev_alarm.to_csv(alarm_file, index=False)\n",
    "        threshold(prev_result['isolation_forest_pred'], alarm_file)\n",
    "    \n",
    "    else:\n",
    "        train_instance = model_train(racks[i], rack_names[i], site_id)\n",
    "        result[i] = train_instance.train_model()\n",
    "        appendDFToCSV_void(result[i], result_file)\n",
    "        threshold(result[i]['isolation_forest_pred'], alarm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_plot(df, variable='cluster', style='*'):\n",
    "    fig,ax = plt.subplots(figsize = (15,10))\n",
    "    for i in df.columns:\n",
    "        if variable in i.lower():\n",
    "            unique_val = df[i].unique()\n",
    "            for j in unique_val:\n",
    "                ax.plot(df[i][df[i] == j], '.', label=(i+' '+str(j)))\n",
    "                ax.legend()\n",
    "            \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_plot(result[0], 'isol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0][result[0]['isolation_forest_pred'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
